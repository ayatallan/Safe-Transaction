{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba2f8bde",
   "metadata": {},
   "source": [
    "In this Notebook, My aim is to implement an unsupervised machine learning approach using a one- class of Support Vector Machine (SVM) and Autoencoder algorithms. The objective is to identify fraudulent transactions within the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3419a7a",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da63156e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Data:\n",
      "      Transaction Date            Card Type Channel  Transaction Type  \\\n",
      "0            2023-01-01  Visa Classic Debit      ATM       Withdrawal   \n",
      "1            2023-01-01  Visa Classic Debit      ATM       Withdrawal   \n",
      "2            2023-01-01  Visa Classic Debit      POS         Purchase   \n",
      "3            2023-01-01  Visa Classic Debit      ATM       Withdrawal   \n",
      "4            2023-01-01  Visa Classic Debit      ATM       Withdrawal   \n",
      "...                 ...                 ...      ...              ...   \n",
      "82629        2023-06-30  Visa Classic Debit      POS         Purchase   \n",
      "82630        2023-06-30  Visa Classic Debit      ATM       Withdrawal   \n",
      "82631        2023-06-30  Visa Classic Debit      ATM       Withdrawal   \n",
      "82632        2023-06-30  Visa Classic Debit      POS         Purchase   \n",
      "82633        2023-06-30  Visa Classic Debit      POS         Purchase   \n",
      "\n",
      "      Transaction Type Group  Entry Mode Transaction Status  Merchant Country  \\\n",
      "0           ATM Transactions  Chip & Pin           PROCESSED        Palestine   \n",
      "1           ATM Transactions  Chip & Pin           PROCESSED        Palestine   \n",
      "2                  Purchases  Chip & Pin           PROCESSED        Palestine   \n",
      "3           ATM Transactions  Chip & Pin           PROCESSED        Palestine   \n",
      "4           ATM Transactions       Other           PROCESSED        Palestine   \n",
      "...                      ...         ...                 ...              ...   \n",
      "82629              Purchases     Paywave           PROCESSED        Palestine   \n",
      "82630       ATM Transactions       Other           PROCESSED        Palestine   \n",
      "82631       ATM Transactions       Other           PROCESSED        Palestine   \n",
      "82632              Purchases     Paywave           PROCESSED        Palestine   \n",
      "82633              Purchases     Paywave           PROCESSED        Palestine   \n",
      "\n",
      "                 Merchant Activity   Amount USD  \n",
      "0      Cash withdrawal from the ATM     -86.460  \n",
      "1      Cash withdrawal from the ATM     -28.820  \n",
      "2      Supermarkets & Confectionary     -14.409  \n",
      "3      Cash withdrawal from the ATM    -317.000  \n",
      "4      Cash withdrawal from the ATM     -43.230  \n",
      "...                             ...         ...  \n",
      "82629  Supermarkets & Confectionary      -5.205  \n",
      "82630  Cash withdrawal from the ATM    -600.000  \n",
      "82631  Cash withdrawal from the ATM   -1000.000  \n",
      "82632   Entertainment & Restaurants      -2.466  \n",
      "82633   Entertainment & Restaurants     -26.301  \n",
      "\n",
      "[82634 rows x 10 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sama Zuhd\\AppData\\Local\\Temp\\ipykernel_18196\\2724529101.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_data['Merchant Activity '] = selected_data['Merchant Activity '].str.replace('other', 'Other', case=False)\n",
      "C:\\Users\\Sama Zuhd\\AppData\\Local\\Temp\\ipykernel_18196\\2724529101.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_data['Transaction Date '] = pd.to_datetime(selected_data['Transaction Date '])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('palpay data new.csv')\n",
    "\n",
    "# List of columns will be included in the modeling \n",
    "selected_columns = ['Transaction Date ', 'Card Type', 'Channel ', 'Transaction Type',\n",
    "                    'Transaction Type Group', 'Entry Mode', 'Transaction Status ',\n",
    "                    'Merchant Country', 'Merchant Activity ', 'Amount USD']\n",
    "\n",
    "# Create a new DataFrame with the selected columns\n",
    "selected_data = data[selected_columns]\n",
    "selected_data['Merchant Activity '] = selected_data['Merchant Activity '].str.replace('other', 'Other', case=False)\n",
    "selected_data['Transaction Date '] = pd.to_datetime(selected_data['Transaction Date '])\n",
    "# Print the new DataFrame\n",
    "print(\"Selected Data:\")\n",
    "print(selected_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1419010",
   "metadata": {},
   "source": [
    "### Data Normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10dcb2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After normalization:\n",
      "0        0.536271\n",
      "1        0.545326\n",
      "2        0.547590\n",
      "3        0.500053\n",
      "4        0.543062\n",
      "           ...   \n",
      "82629    0.549036\n",
      "82630    0.455593\n",
      "82631    0.392753\n",
      "82632    0.549466\n",
      "82633    0.545722\n",
      "Name: Amount USD, Length: 82634, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sama Zuhd\\AppData\\Local\\Temp\\ipykernel_18196\\2444275877.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_data['Amount USD'] = (amount_usd - min_amount_usd) / (max_amount_usd - min_amount_usd)\n"
     ]
    }
   ],
   "source": [
    "amount_usd = selected_data['Amount USD']\n",
    "min_amount_usd = amount_usd.min()\n",
    "max_amount_usd = amount_usd.max()\n",
    "selected_data['Amount USD'] = (amount_usd - min_amount_usd) / (max_amount_usd - min_amount_usd)\n",
    "\n",
    "print(\"\\nAfter normalization:\")\n",
    "print(selected_data['Amount USD'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3039367",
   "metadata": {},
   "source": [
    "### One-Hot Encoding For the categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57c8b6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Data:\n",
      "  Transaction Date   Amount USD  Card Type_Visa Classic Debit  \\\n",
      "0        2023-01-01    0.536271                             1   \n",
      "1        2023-01-01    0.545326                             1   \n",
      "2        2023-01-01    0.547590                             1   \n",
      "3        2023-01-01    0.500053                             1   \n",
      "4        2023-01-01    0.543062                             1   \n",
      "\n",
      "   Card Type_Visa Platinum Debit  Card Type_Visa Virtual Debit  Channel _ATM  \\\n",
      "0                              0                             0             1   \n",
      "1                              0                             0             1   \n",
      "2                              0                             0             0   \n",
      "3                              0                             0             1   \n",
      "4                              0                             0             1   \n",
      "\n",
      "   Channel _E-Commerce  Channel _POS  Transaction Type Group_ATM Transactions  \\\n",
      "0                    0             0                                        1   \n",
      "1                    0             0                                        1   \n",
      "2                    0             1                                        0   \n",
      "3                    0             0                                        1   \n",
      "4                    0             0                                        1   \n",
      "\n",
      "   Transaction Type Group_Purchases  ...  \\\n",
      "0                                 0  ...   \n",
      "1                                 0  ...   \n",
      "2                                 1  ...   \n",
      "3                                 0  ...   \n",
      "4                                 0  ...   \n",
      "\n",
      "   Merchant Activity _Utilities (electric,gas,water)  \\\n",
      "0                                                  0   \n",
      "1                                                  0   \n",
      "2                                                  0   \n",
      "3                                                  0   \n",
      "4                                                  0   \n",
      "\n",
      "   Merchant Activity _libraries and bookstores  Region_Africa  Region_Asia  \\\n",
      "0                                            0              0            0   \n",
      "1                                            0              0            0   \n",
      "2                                            0              0            0   \n",
      "3                                            0              0            0   \n",
      "4                                            0              0            0   \n",
      "\n",
      "   Region_Europe  Region_Middle East  Region_Middle East/North Africa  \\\n",
      "0              0                   0                                0   \n",
      "1              0                   0                                0   \n",
      "2              0                   0                                0   \n",
      "3              0                   0                                0   \n",
      "4              0                   0                                0   \n",
      "\n",
      "   Region_North America  Region_Oceania  Region_South America  \n",
      "0                     0               0                     0  \n",
      "1                     0               0                     0  \n",
      "2                     0               0                     0  \n",
      "3                     0               0                     0  \n",
      "4                     0               0                     0  \n",
      "\n",
      "[5 rows x 43 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of categorical columns to encode\n",
    "categorical_columns = ['Card Type', 'Channel ', 'Transaction Type Group', 'Entry Mode', 'Transaction Status ','Transaction Type','Merchant Activity ']\n",
    "\n",
    "# Apply One-Hot Encoding to the categorical columns\n",
    "encoded_data = pd.get_dummies(selected_data, columns=categorical_columns)\n",
    "\n",
    "# Clean 'Merchant Country' column by mapping to regions\n",
    "country_to_region = {\n",
    "    'egypt': 'Middle East/North Africa',\n",
    "    'netherlands': 'Europe',\n",
    "    'visa_ie': 'Europe',\n",
    "    'united states': 'North America',\n",
    "    'germany,federal repu': 'Europe',\n",
    "    'luxembourg': 'Europe',\n",
    "    'united kingdom': 'Europe',\n",
    "    'israel': 'Middle East',\n",
    "    'singapore': 'Asia',\n",
    "    'jordan': 'Middle East/North Africa',\n",
    "    'cyprus': 'Europe',\n",
    "    'france': 'Europe',\n",
    "    'czech republic': 'Europe',\n",
    "    'hong kong': 'Asia',\n",
    "    'qatar': 'Middle East',\n",
    "    'austria': 'Europe',\n",
    "    'lebanon': 'Middle East/North Africa',\n",
    "    'turkey': 'Middle East',\n",
    "    'united arab emirates': 'Middle East',\n",
    "    'sweden': 'Europe',\n",
    "    'switzerland': 'Europe',\n",
    "    'spain': 'Europe',\n",
    "    'australia': 'Oceania',\n",
    "    'malta': 'Europe',\n",
    "    'pakistan': 'Asia',\n",
    "    'romania': 'Europe',\n",
    "    'iraq': 'Middle East',\n",
    "    'poland': 'Europe',\n",
    "    'kazakhstan': 'Asia',\n",
    "    'bulgaria': 'Europe',\n",
    "    'thailand': 'Asia',\n",
    "    'india': 'Asia',\n",
    "    'lithuania': 'Europe',\n",
    "    'finland': 'Europe',\n",
    "    'canada': 'North America',\n",
    "    'saudi arabia': 'Middle East',\n",
    "    'japan': 'Asia',\n",
    "    'morocco': 'Middle East/North Africa',\n",
    "    'hungary': 'Europe',\n",
    "    'kenya': 'Africa',\n",
    "    'estonia': 'Europe',\n",
    "    'rwanda': 'Africa',\n",
    "    'malaysia': 'Asia',\n",
    "    'denmark': 'Europe',\n",
    "    'italy': 'Europe',\n",
    "    'brazil': 'South America',\n",
    "    'nigeria': 'Africa',\n",
    "    'kuwait': 'Middle East',\n",
    "    'cambodia': 'Asia',\n",
    "    'moldova, rep. of': 'Europe',\n",
    "    'gibraltar': 'Europe',\n",
    "    'slovenia': 'Europe',\n",
    "    'ukrainian ssr': 'Europe',\n",
    "}\n",
    "encoded_data['Merchant Country'] = encoded_data['Merchant Country'].str.strip().str.lower()\n",
    "encoded_data['Merchant Country'] = encoded_data['Merchant Country'].map(country_to_region)\n",
    "\n",
    "# Apply One-Hot Encoding to the 'Merchant Country' column to create region-based columns\n",
    "encoded_data = pd.get_dummies(encoded_data, columns=['Merchant Country'], prefix='Region')\n",
    "\n",
    "# Print the encoded data\n",
    "print(\"Encoded Data:\")\n",
    "print(encoded_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5f8d8e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Transaction Date ', 'Amount USD', 'Card Type_Visa Classic Debit',\n",
      "       'Card Type_Visa Platinum Debit', 'Card Type_Visa Virtual Debit',\n",
      "       'Channel _ATM', 'Channel _E-Commerce', 'Channel _POS',\n",
      "       'Transaction Type Group_ATM Transactions',\n",
      "       'Transaction Type Group_Purchases', 'Entry Mode_Chip & Pin',\n",
      "       'Entry Mode_E-commerce', 'Entry Mode_Magnetic Stripe',\n",
      "       'Entry Mode_Manual', 'Entry Mode_Other', 'Entry Mode_Paywave',\n",
      "       'Transaction Status _PROCESSED', 'Transaction Status _REVERSED',\n",
      "       'Transaction Type_Deposit', 'Transaction Type_Purchase',\n",
      "       'Transaction Type_Withdrawal',\n",
      "       'Merchant Activity _Advertising services',\n",
      "       'Merchant Activity _Cash withdrawal from the ATM',\n",
      "       'Merchant Activity _Clothing & Jewelry',\n",
      "       'Merchant Activity _Electronics',\n",
      "       'Merchant Activity _Entertainment & Restaurants',\n",
      "       'Merchant Activity _Fuel Stations',\n",
      "       'Merchant Activity _Government and institutional services',\n",
      "       'Merchant Activity _Health and Beauty', 'Merchant Activity _Other',\n",
      "       'Merchant Activity _Subscriptions & Memberships',\n",
      "       'Merchant Activity _Supermarkets & Confectionary',\n",
      "       'Merchant Activity _Travel & Tourism',\n",
      "       'Merchant Activity _Utilities (electric,gas,water)',\n",
      "       'Merchant Activity _libraries and bookstores', 'Region_Africa',\n",
      "       'Region_Asia', 'Region_Europe', 'Region_Middle East',\n",
      "       'Region_Middle East/North Africa', 'Region_North America',\n",
      "       'Region_Oceania', 'Region_South America'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(encoded_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "199cbd8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transaction Date                                            datetime64[ns]\n",
      "Amount USD                                                         float64\n",
      "Card Type_Visa Classic Debit                                         uint8\n",
      "Card Type_Visa Platinum Debit                                        uint8\n",
      "Card Type_Visa Virtual Debit                                         uint8\n",
      "Channel _ATM                                                         uint8\n",
      "Channel _E-Commerce                                                  uint8\n",
      "Channel _POS                                                         uint8\n",
      "Transaction Type Group_ATM Transactions                              uint8\n",
      "Transaction Type Group_Purchases                                     uint8\n",
      "Entry Mode_Chip & Pin                                                uint8\n",
      "Entry Mode_E-commerce                                                uint8\n",
      "Entry Mode_Magnetic Stripe                                           uint8\n",
      "Entry Mode_Manual                                                    uint8\n",
      "Entry Mode_Other                                                     uint8\n",
      "Entry Mode_Paywave                                                   uint8\n",
      "Transaction Status _PROCESSED                                        uint8\n",
      "Transaction Status _REVERSED                                         uint8\n",
      "Transaction Type_Deposit                                             uint8\n",
      "Transaction Type_Purchase                                            uint8\n",
      "Transaction Type_Withdrawal                                          uint8\n",
      "Merchant Activity _Advertising services                              uint8\n",
      "Merchant Activity _Cash withdrawal from the ATM                      uint8\n",
      "Merchant Activity _Clothing & Jewelry                                uint8\n",
      "Merchant Activity _Electronics                                       uint8\n",
      "Merchant Activity _Entertainment & Restaurants                       uint8\n",
      "Merchant Activity _Fuel Stations                                     uint8\n",
      "Merchant Activity _Government and institutional services             uint8\n",
      "Merchant Activity _Health and Beauty                                 uint8\n",
      "Merchant Activity _Other                                             uint8\n",
      "Merchant Activity _Subscriptions & Memberships                       uint8\n",
      "Merchant Activity _Supermarkets & Confectionary                      uint8\n",
      "Merchant Activity _Travel & Tourism                                  uint8\n",
      "Merchant Activity _Utilities (electric,gas,water)                    uint8\n",
      "Merchant Activity _libraries and bookstores                          uint8\n",
      "Region_Africa                                                        uint8\n",
      "Region_Asia                                                          uint8\n",
      "Region_Europe                                                        uint8\n",
      "Region_Middle East                                                   uint8\n",
      "Region_Middle East/North Africa                                      uint8\n",
      "Region_North America                                                 uint8\n",
      "Region_Oceania                                                       uint8\n",
      "Region_South America                                                 uint8\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(encoded_data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6903fb5",
   "metadata": {},
   "source": [
    "### One-Class SVM Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15e4c999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of anomalies: 5.094693531796454\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "# Drop 'Transaction Date' column as it may not directly contribute to anomaly detection\n",
    "encoded_data = encoded_data.drop(['Transaction Date '], axis=1)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test = train_test_split(encoded_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Apply One-Class SVM\n",
    "ocsvm = OneClassSVM(nu=0.05, kernel='rbf', gamma='scale')  \n",
    "ocsvm.fit(X_train_scaled)\n",
    "\n",
    "# Predict on the test set\n",
    "predictions = ocsvm.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model (based on percentage of predicted anomalies)\n",
    "anomaly_percentage = (sum(predictions == -1) / len(predictions)) * 100\n",
    "\n",
    "print(\"Percentage of anomalies:\", anomaly_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c54410f",
   "metadata": {},
   "source": [
    "### Apply  Autoencoders (for neural network-based anomaly detection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8991d6b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1860/1860 [==============================] - 4s 2ms/step - loss: 0.0951 - val_loss: 0.0361\n",
      "Epoch 2/50\n",
      "1860/1860 [==============================] - 3s 2ms/step - loss: 0.0321 - val_loss: 0.0350\n",
      "Epoch 3/50\n",
      "1860/1860 [==============================] - 3s 2ms/step - loss: 0.0357 - val_loss: 0.0065\n",
      "Epoch 4/50\n",
      "1860/1860 [==============================] - 3s 2ms/step - loss: 0.0315 - val_loss: 0.0111\n",
      "Epoch 5/50\n",
      "1860/1860 [==============================] - 3s 2ms/step - loss: 0.0201 - val_loss: 0.0064\n",
      "Epoch 6/50\n",
      "1860/1860 [==============================] - 3s 2ms/step - loss: 0.0176 - val_loss: 0.0048\n",
      "Epoch 7/50\n",
      "1860/1860 [==============================] - 3s 2ms/step - loss: 0.0198 - val_loss: 0.0075\n",
      "Epoch 8/50\n",
      "1860/1860 [==============================] - 3s 2ms/step - loss: 0.0155 - val_loss: 0.0164\n",
      "Epoch 9/50\n",
      "1860/1860 [==============================] - 3s 2ms/step - loss: 0.0171 - val_loss: 0.0057\n",
      "Epoch 10/50\n",
      "1860/1860 [==============================] - 3s 1ms/step - loss: 0.0105 - val_loss: 0.0049\n",
      "Epoch 11/50\n",
      "1860/1860 [==============================] - 5s 3ms/step - loss: 0.0155 - val_loss: 0.0141\n",
      "Epoch 12/50\n",
      "1860/1860 [==============================] - 4s 2ms/step - loss: 0.0145 - val_loss: 0.0036\n",
      "Epoch 13/50\n",
      "1860/1860 [==============================] - 3s 2ms/step - loss: 0.0125 - val_loss: 0.0087\n",
      "Epoch 14/50\n",
      "1860/1860 [==============================] - 4s 2ms/step - loss: 0.0126 - val_loss: 0.0035\n",
      "Epoch 15/50\n",
      "1860/1860 [==============================] - 3s 1ms/step - loss: 0.0107 - val_loss: 0.0040\n",
      "Epoch 16/50\n",
      "1860/1860 [==============================] - 3s 2ms/step - loss: 0.0176 - val_loss: 0.0027\n",
      "Epoch 17/50\n",
      "1860/1860 [==============================] - 3s 1ms/step - loss: 0.0086 - val_loss: 0.0039\n",
      "Epoch 18/50\n",
      "1860/1860 [==============================] - 4s 2ms/step - loss: 0.0090 - val_loss: 0.0037\n",
      "Epoch 19/50\n",
      "1860/1860 [==============================] - 3s 2ms/step - loss: 0.0139 - val_loss: 0.0057\n",
      "Epoch 20/50\n",
      "1860/1860 [==============================] - 3s 2ms/step - loss: 0.0106 - val_loss: 0.0055\n",
      "Epoch 21/50\n",
      "1860/1860 [==============================] - 3s 1ms/step - loss: 0.0067 - val_loss: 0.0030\n",
      "Epoch 22/50\n",
      "1860/1860 [==============================] - 3s 2ms/step - loss: 0.0119 - val_loss: 0.0065\n",
      "Epoch 23/50\n",
      "1860/1860 [==============================] - 4s 2ms/step - loss: 0.0065 - val_loss: 0.0035\n",
      "Epoch 24/50\n",
      "1860/1860 [==============================] - 4s 2ms/step - loss: 0.0137 - val_loss: 0.0038\n",
      "Epoch 25/50\n",
      "1860/1860 [==============================] - 3s 2ms/step - loss: 0.0061 - val_loss: 0.0015\n",
      "Epoch 26/50\n",
      "1860/1860 [==============================] - 3s 1ms/step - loss: 0.0091 - val_loss: 0.0049\n",
      "Epoch 27/50\n",
      "1860/1860 [==============================] - 4s 2ms/step - loss: 0.0122 - val_loss: 0.0029\n",
      "Epoch 28/50\n",
      "1860/1860 [==============================] - 5s 3ms/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 29/50\n",
      "1860/1860 [==============================] - 4s 2ms/step - loss: 0.0139 - val_loss: 0.0037\n",
      "Epoch 30/50\n",
      "1860/1860 [==============================] - 4s 2ms/step - loss: 0.0061 - val_loss: 0.0028\n",
      "Epoch 31/50\n",
      "1860/1860 [==============================] - 4s 2ms/step - loss: 0.0042 - val_loss: 0.0021\n",
      "Epoch 32/50\n",
      "1860/1860 [==============================] - 3s 2ms/step - loss: 0.0102 - val_loss: 0.0018\n",
      "Epoch 33/50\n",
      "1860/1860 [==============================] - 3s 2ms/step - loss: 0.0080 - val_loss: 0.0024\n",
      "Epoch 34/50\n",
      "1860/1860 [==============================] - 4s 2ms/step - loss: 0.0094 - val_loss: 0.0041\n",
      "Epoch 35/50\n",
      "1860/1860 [==============================] - 3s 2ms/step - loss: 0.0104 - val_loss: 0.0034\n",
      "Epoch 36/50\n",
      "1860/1860 [==============================] - 3s 2ms/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 37/50\n",
      "1860/1860 [==============================] - 3s 2ms/step - loss: 0.0095 - val_loss: 0.0032\n",
      "Epoch 38/50\n",
      "1860/1860 [==============================] - 3s 2ms/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 39/50\n",
      "1860/1860 [==============================] - 3s 2ms/step - loss: 0.0116 - val_loss: 0.0027\n",
      "Epoch 40/50\n",
      "1860/1860 [==============================] - 4s 2ms/step - loss: 0.0060 - val_loss: 0.0018\n",
      "Epoch 41/50\n",
      "1860/1860 [==============================] - 3s 2ms/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 42/50\n",
      "1860/1860 [==============================] - 3s 1ms/step - loss: 0.0124 - val_loss: 0.0018\n",
      "Epoch 43/50\n",
      "1860/1860 [==============================] - 3s 2ms/step - loss: 0.0043 - val_loss: 0.0015\n",
      "Epoch 44/50\n",
      "1860/1860 [==============================] - 3s 2ms/step - loss: 0.0155 - val_loss: 0.0016\n",
      "Epoch 45/50\n",
      "1860/1860 [==============================] - 3s 2ms/step - loss: 0.0055 - val_loss: 0.0024\n",
      "Epoch 46/50\n",
      "1860/1860 [==============================] - 3s 2ms/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 47/50\n",
      "1860/1860 [==============================] - 3s 1ms/step - loss: 0.0114 - val_loss: 0.0034\n",
      "Epoch 48/50\n",
      "1860/1860 [==============================] - 4s 2ms/step - loss: 0.0038 - val_loss: 0.0016\n",
      "Epoch 49/50\n",
      "1860/1860 [==============================] - 4s 2ms/step - loss: 0.0090 - val_loss: 0.0021\n",
      "Epoch 50/50\n",
      "1860/1860 [==============================] - 4s 2ms/step - loss: 0.0056 - val_loss: 0.0025\n",
      "517/517 [==============================] - 1s 892us/step\n",
      "Mean Squared Error: 0.0025344921726770673\n",
      "Indices of detected anomalies: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense\n",
    "\n",
    "\n",
    "# Drop 'Transaction Date' column as it may not directly contribute to anomaly detection\n",
    "# encoded_data = encoded_data.drop(['Transaction Date '], axis=1)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test = train_test_split(encoded_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Build and train the Autoencoder\n",
    "input_dim = X_train_scaled.shape[1]\n",
    "\n",
    "autoencoder = Sequential()\n",
    "autoencoder.add(Dense(128, activation='relu', input_dim=input_dim))\n",
    "autoencoder.add(Dense(64, activation='relu'))\n",
    "autoencoder.add(Dense(128, activation='relu'))\n",
    "autoencoder.add(Dense(input_dim, activation='linear'))\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "autoencoder.fit(X_train_scaled, X_train_scaled, epochs=50, batch_size=32, shuffle=True, validation_split=0.1)\n",
    "\n",
    "# Evaluate the Autoencoder on the test set\n",
    "X_test_pred = autoencoder.predict(X_test_scaled)\n",
    "mse = mean_squared_error(X_test_scaled, X_test_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Set a threshold for anomaly detection based on reconstruction error\n",
    "threshold = mse * 2\n",
    "\n",
    "# Predict anomalies based on the threshold\n",
    "anomalies = np.where(mse > threshold)[0]\n",
    "\n",
    "print(\"Indices of detected anomalies:\", anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10d9272c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sama Zuhd\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model and scaler\n",
    "autoencoder.save(\"autoencoder_model.h5\")\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "\n",
    "# Load the model and scaler\n",
    "loaded_model = load_model(\"autoencoder_model.h5\")\n",
    "loaded_scaler = joblib.load(\"scaler.pkl\")\n",
    "\n",
    "# Define a function for fraud detection using the loaded model and scaler\n",
    "def detect_fraud(model, scaler, transactions):\n",
    "    transactions_scaled = scaler.transform(transactions)\n",
    "    transactions_pred = model.predict(transactions_scaled)\n",
    "    mse = np.mean(np.power(transactions_scaled - transactions_pred, 2), axis=1)\n",
    "    \n",
    "    threshold = mse * 2  # You can adjust the threshold as needed\n",
    "    fraud_indices = np.where(mse > threshold)[0]\n",
    "    \n",
    "    fraud_predictions = np.zeros(len(transactions))\n",
    "    fraud_predictions[fraud_indices] = 1\n",
    "    \n",
    "    return fraud_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d5754e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
